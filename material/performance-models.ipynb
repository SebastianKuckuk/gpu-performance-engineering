{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6375a92c-c9ee-42c9-9b83-2c769350b66a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Performance Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5703fcea-47be-4fca-9497-6c961624785b",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87978e7-04f5-497b-9143-0d93bfe06cba",
   "metadata": {},
   "source": [
    "Performance models provide simplified yet effective frameworks to analyze and predict the performance of GPU kernels.\n",
    "Their main aim is\n",
    "* **Predict** performance of (parts of) applications\n",
    "* **Relate** observed performance to hardware characteristics\n",
    "* Evaluate whether spending time on (further) optimizing the code is promising\n",
    "* **Guide** optimization efforts by identifying performance bottlenecks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c54b75",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Bottleneck Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d4b5f3",
   "metadata": {},
   "source": [
    "The bottleneck model analyzes potential performance limiters individually, such as:\n",
    "* **DRAM Bandwidth**, i.e. the speed at which data can be transferred from/ to global memory.\n",
    "* **Compute Throughput**, i.e. the rate at which computations can be executed.\n",
    "* **Cache Bandwidth**, i.e. the speed of accessing data from different parts of the memory hierarchy, e.g. L2 cache, L1 cache, or shared memory.\n",
    "\n",
    "Each bottleneck is modeled separately to estimate its contribution to the total execution time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6b4830",
   "metadata": {},
   "source": [
    "### Steps to Apply the Bottleneck Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a72d7e7",
   "metadata": {},
   "source": [
    "1. For each potential bottleneck, calculate the time required for the kernel to execute assuming it is limited by that bottleneck.\n",
    "2. Take the maximum of the single contributions to estimate the total execution time.\n",
    "3. Compare the predicted time to the actual run time.\n",
    "   * The interpretation of the (potential) difference is similar to that of the roofline model (see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d74211d-befc-48d1-a1a2-00857d3b1841",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Roofline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab51f748-9f65-4300-85f3-d6c691e9ad98",
   "metadata": {},
   "source": [
    "The roofline model is one of the most widely used performance models in GPU computing.\n",
    "It highlights two primary performance limiters for a kernel:\n",
    "1. **Computational Throughput**, i.e. how fast the GPU can perform the required computations.\n",
    "2. **Memory Bandwidth** (data throughput), i.e. how fast data can be transferred to and from execution units."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88939b1-ea51-460b-8719-b017f712596b",
   "metadata": {},
   "source": [
    "The *model* is parameterized with theoretical limits for both, where they are either\n",
    "- **Theoretical Peak Values** to provide optimistic performance limits based on GPU architecture (see the [GPU architecture](gpu-architecture.ipynb) notebook).\n",
    "- **Benchmark Values** obtained through micro benchmarks (see the [Micro Benchmarks](micro-benchmarks.ipynb) notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d810df-636b-4121-ac08-55810d4f62d1",
   "metadata": {},
   "source": [
    "The *application* code is represented by its ratio of computations to memory traffic:\n",
    "\n",
    " **Arithmetic Intensity (AI) = FLOPs (Floating Point Operations) / Bytes Transferred**.\n",
    "\n",
    "* **High AI** points at a code likely bound by computational throughput.\n",
    "    * Examples are (dense) matrix-matrix multiplications, fast Fourier transforms (FFT), and many operations in deep neural nets (DNN).\n",
    "* **Low AI** points at a code likely bound by memory bandwidth.\n",
    "    * Examples are sparse matrix-vector multiplications (incl. stencil applications), histogram computations, and vector operations (init, copy, ...)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727cb8a1-d019-4a8e-bce0-3159f9015ecd",
   "metadata": {},
   "source": [
    "### Steps to Apply the Roofline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c80fc7-53bf-4516-a11c-bf9e531fc0f9",
   "metadata": {},
   "source": [
    "1. Identify GPU-specific compute and memory bandwidth limits.\n",
    "2. Calculate the arithmetic intensity of the kernel to be modelled.\n",
    "3. Map the kernel's AI onto the Roofline chart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f7ba0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/b/b1/Example_of_a_Roofline_model.svg\" alt=\"roofline example\" width=\"768px\" style=\"background-color:white\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4bf00e-90ca-436c-8690-ec563927e2d2",
   "metadata": {},
   "source": [
    "While setting up roofline models by hand can give valuable insights, it can also be cumbersome in practice.\n",
    "One alternative is using profiling tools to automate (parts of) the process, e.g. Nsight Compute as discussed in the [Kernel Level Profiling](./kernel-level-profiling.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eff464a",
   "metadata": {},
   "source": [
    "<img src=\"img/ncu-roofline.png\" alt=\"ncu roofline\" width=\"768px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da5ea2d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e0a0d1",
   "metadata": {},
   "source": [
    "* Compute the *machine balance* (ridge point of the roofline) for the **A40**, **A100** (80 GB) and **H100** (94 GB) GPUs as discussed in the [GPU Architecture](./gpu-architecture.ipynb) notebook.\n",
    "* Compute the *arithmetic intensity* of the [2D stencil test case](../src/stencil-2d/stencil-2d-base.cpp).\n",
    "* Do both tasks for **single** and **double precision** floating point operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19518fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a27202d",
   "metadata": {},
   "source": [
    "**Machine balance**\n",
    "\n",
    "| GPU  |         SP         |          DP           |\n",
    "| ---- | :----------------: | :-------------------: |\n",
    "| A40  | **~53** (37 / 0.7) | **~0.8** (0.59 / 0.7) |\n",
    "| A100 |  **~9** (19 / 2)   |   **~5** (9.75 / 2)   |\n",
    "| H100 | **~28** (67 / 2.4) |  **~14** (34 / 2.4)   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7870ccd7",
   "metadata": {},
   "source": [
    "**Arithmetic intensity**\n",
    "\n",
    "| App        |        SP        |          DP           |\n",
    "| ---------- | :--------------: | :-------------------: |\n",
    "| Stencil-2D | **~0.9** (7 / 8) | DP: **~0.4** (7 / 16) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372d557e-59af-4f52-a96c-23e6b71f11a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Interpreting the Roofline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60832173-e510-4bc6-9718-a40105196b75",
   "metadata": {},
   "source": [
    "The Roofline Model offers a quick estimate of the best-case performance of your code on a given GPU, as well as the available optimization potential.\n",
    "Generally, there are three major outcome possibilities:\n",
    "* Measured performance near roofline\n",
    "    * suggests that the kernel's performance is hitting hardware limits and that\n",
    "    * further optimization is only viable if the primary bottleneck can be addressed.\n",
    "* Measured performance exceeds roofline\n",
    "    * corresponds to at least one assumption made not holding, e.g.\n",
    "    * the number of flops is lower due to compiler optimizations such as removal of redundant computations, or\n",
    "    * the number of bytes transferred is lower due to caching of data or usage of already cached data.\n",
    "* Measured performance below prediction\n",
    "    *  indicates either model inconsistencies, e.g. modeling for a different data type than is actually used, or\n",
    "    *  optimization potential that can frequently be attributed to common patterns (also discussed in more detail in the [Micro Benchmarks](./micro-benchmarks.ipynb) notebook), e.g.\n",
    "        * **Uncoalesced Memory Accesses** from, e.g., strided or random access patterns. This leads to more bytes transferred than required.\n",
    "        * **Occupancy Problems** due to launching too few threads, choosing non-optimal block sizes or over-utilizing common resources such as shared memory.\n",
    "        * **Thread Divergence** due to divergent branching in warps.\n",
    "        * **Serialization Effects** from heavily using synchronization functionalities, or from a high degree of atomic congestion.\n",
    "        * **Load Imbalances** either due to varying workload per thread or due to partial waves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77df3da3-0096-42ea-847c-46fdbf96410f",
   "metadata": {},
   "source": [
    "Besides being able to estimate the efficiency with which a given kernel runs on a given GPU, roofline models also allow estimating how a kernel would perform on a *different* GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88723b55-8bb3-45d2-acd0-980f74bfbb1c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Extended Roofline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcda563-695a-4eca-9007-97a1bbf467ea",
   "metadata": {},
   "source": [
    "The classical roofline model can be extended to include additional effects, including\n",
    "* Performing computations with **different data types** which introduces additional AI values as well as additional, potentially different computational throughput limits\n",
    "* Modelling transfers from/ to different **cache levels** which can be helpful when modelling\n",
    "    * kernels where (part of) the read data is already in the L2 cache from a previous kernel\n",
    "    * kernels that are limited by the available L2 bandwidth\n",
    "    * kernels that write only a small amount of memory which gets cached in L2, i.e. is not directly written to DRAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbbd5f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Next Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9d0205",
   "metadata": {},
   "source": [
    "Next, we use micro benchmarks to assess realistic performance limits and to investigate some of the common performance limiting patterns mentioned above.\n",
    "Head over to the [Micro Benchmarks](./micro-benchmarks.ipynb) notebook to get started."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
